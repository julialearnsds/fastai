{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "720523f5",
   "metadata": {},
   "source": [
    "## Penguin Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c1fe6",
   "metadata": {},
   "source": [
    "Chapter 2 of the fastai book details and Image Classifier with a bear example. We are prompted to create our own classifier model try out deployment with an app.\n",
    "\n",
    "The aim of this project is to create a model to classify three penguin species. Using Bing Search to download images as described in the book, a CNN learner is fine-tuned, and the project deployed using an in-notebook application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4456f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31e5663",
   "metadata": {},
   "source": [
    "To set up the Bing Search, sign into Microsoft Azure account and paste your key in as the second argument. We then specify the species of penguins in `penguin_types` and create a folder called Penguins to store the downloaded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f5a2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ.get('AZURE_SEARCH_KEY', 'f545086c6fb74ceeb77ac5f3bbe0d81d')\n",
    "penguin_types = 'african','king','emporer'\n",
    "path = Path('Penguins')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce091c72",
   "metadata": {},
   "source": [
    "Create a for loop that searches Bing for each penguin species specified in `penguin_types`, and downloads these images into seperate folders within the Penguin folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b55acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for o in penguin_types:\n",
    "        dest = (path/o) # initiate naming for the folders for each species\n",
    "        dest.mkdir(exist_ok=True) # create folders\n",
    "        results = search_images_bing(key, f'{o} penguin') # search Bing for images\n",
    "        download_images(dest, urls=results.attrgot('contentUrl')) # download images to the destination folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564c36f",
   "metadata": {},
   "source": [
    "Our folder has image files in it, we want to make sure that all images used aren't corrupt. `verify_images` checks this for us, and to remove them, we `unlink` each one from the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969fb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = get_image_files(path)\n",
    "failed = verify_images(fns)\n",
    "failed.map(Path.unlink);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375e0d9",
   "metadata": {},
   "source": [
    "Now, we will create a `DataBlock` object. This is like a template for creating a `Dataloaders` that will tell fastai four things about the data:\n",
    "- What kind of data we have\n",
    "- How to get the items\n",
    "- How to split the data into training and validation sets\n",
    "- How to label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "137b36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), # independent variable and dependent variable (african, king, emporer)\n",
    "    get_items=get_image_files, # how to get the files\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42), # how to split the data - split data randomly, with 20% validation\n",
    "    get_y=parent_label, # how to label the data - parent_label gets the name of the folder it is in\n",
    "    item_tfms=Resize(128)) # function applied to each image - resize them to 128x128 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a10cb",
   "metadata": {},
   "source": [
    "As our dataset is quite small - 150 images of each species at most - we'll use `RandomResizedCrop` on each image size of 224 pixels (which is standard for image classification) and the default `aug_transforms` on the batch. These batch augmentations include image rotation, warping and contrast changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf6aa87d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "penguins = penguins.new(\n",
    "    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms())\n",
    "dls = penguins.dataloaders(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18fc711",
   "metadata": {},
   "source": [
    "Now to train the classifier. We can now create the `Learner` as a convolutional neural network and specify the architecture.\n",
    "\n",
    "The learner function tries to figure out what the parameters are that best cause the `Dataloaders` to match the labels in the dataset. `resnet` refers to the number of layers in the architecture. The more layers, the longer it'll take, and the more prone to overfitting. Thus, we've gone with `resnet18` - out of the options 18, 34, 50, 101, 152. Then, we define the metric, or the measure of the quality of the model's prediction using the validation set, as `error_rate`. This function will provide the percentage of images in the validation set that are being classified incorrectly after every epoch.\n",
    "\n",
    "In order to fit the model, you need to define how many times each image should be looked at - the number of epochs. This number depends on how much time you have, starting small is okay as you can train it with more later if you have the time. `fine_tune` is used when we are transfer learning - using a pretrained model for a task that is different to what it was originally trained for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2dcd3b",
   "metadata": {},
   "source": [
    "Now that the model has been trained, we can visualise the count of correctly and incorrectly classified images with a confusion matrix. Ideally, we want the negative diagonal to be darkest and add to the total number of observations in our validation set, while the surrounding boxes are light and equal to zero. These off-diagonal boxes represent the model's errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c8e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdeafe7",
   "metadata": {},
   "source": [
    "Loss is a penalty representing how bad the model's incorrect prediction was. We can use `plot_top_losses` to display the images with the highest loss in our dataset to help us distinguish whether the errors are due to a model problem or dataset problem. The values above each image represent the class the model predicted, the actual class, the loss value and the model's probability, or confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(5, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6f21f",
   "metadata": {},
   "source": [
    "The chapter explains that intuitively, data cleaning is conducted before the model is trained. However, in the example, their model has a wrongly classified prediction with high confidence, and it is found that the image was incorrectly labelled to begin with. This reinforces the idea that sometimes, a model can help you find data issues more easily. Thus, they prefer to train a simple model first to assist with data cleaning.\n",
    "\n",
    "In the case where we may need to change the label of an image, `ImageClassifierCleaner` is a GUI (graphical user interface) to manually relabel or remove images from both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = ImageClassifierCleaner(learn)\n",
    "cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88808fd3",
   "metadata": {},
   "source": [
    "We can use the `export` method to save our `Learner` as a file to access later called \"export.pkl\". This will save the model architecture, parameters and the `Dataloaders` so you don't have to define these again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e879d",
   "metadata": {},
   "source": [
    "For deployment, we can create a basic GUI application in the notebook. This will use the model to give a prediction for an image that the user uploads. We will initialise all the bits and pieces we need for it:\n",
    "- A file upload button\n",
    "- An output widget to display the uploaded image\n",
    "- A run button that will initiate the prediction\n",
    "- A label to display the model's prediction of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8651d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload = widgets.FileUpload()\n",
    "out_pl = widgets.Output()\n",
    "btn_run = widgets.Button(description='Classify')\n",
    "lbl_pred = widgets.Label()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0e41b2",
   "metadata": {},
   "source": [
    "We'll create a function called a click event handler is called whenever the button is clicked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eef832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    img = PILImage.create(btn_upload.data[-1]) # create an image from the upload\n",
    "    out_pl.clear_output() # clear the output\n",
    "    with out_pl: display(img.to_thumb(128,128)) # display the image\n",
    "    pred,pred_idx,probs = learn_inf.predict(img) # call the prediction\n",
    "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}' # display the prediction\n",
    "\n",
    "btn_run.on_click(on_click_classify) # on click, run the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b84ec46",
   "metadata": {},
   "source": [
    "Finally, we'll pull all these together into a vertical box, `VBox`. And now our GUI is complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1abf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VBox([widgets.Label('Select your penguin!'), \n",
    "      btn_upload, btn_run, out_pl, lbl_pred])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
